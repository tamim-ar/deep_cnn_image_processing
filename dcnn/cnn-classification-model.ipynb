{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10043545,"sourceType":"datasetVersion","datasetId":6187250}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport glob\nimport os\nimport shutil\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.utils import img_to_array, array_to_img\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFilter\nimport numpy as np\nimport pandas as pd\n\n# Split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\n# Import additional Keras libraries\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping\n\n# Import metrics for evaluating the model\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:20.563417Z","iopub.execute_input":"2024-11-30T18:29:20.563926Z","iopub.status.idle":"2024-11-30T18:29:33.163729Z","shell.execute_reply.started":"2024-11-30T18:29:20.563901Z","shell.execute_reply":"2024-11-30T18:29:33.162997Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Loading","metadata":{}},{"cell_type":"code","source":"# Load dataset\npath = '/kaggle/input/monkey-species-image-final'\npath_imgs = list(glob.glob(path + '/**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:33.165563Z","iopub.execute_input":"2024-11-30T18:29:33.166261Z","iopub.status.idle":"2024-11-30T18:29:33.721970Z","shell.execute_reply.started":"2024-11-30T18:29:33.166225Z","shell.execute_reply":"2024-11-30T18:29:33.721283Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Label Gen","metadata":{}},{"cell_type":"code","source":"labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], path_imgs))\nfile_path = pd.Series(path_imgs, name='File_Path').astype(str)\nlabels = pd.Series(labels, name='Labels')","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:33.722865Z","iopub.execute_input":"2024-11-30T18:29:33.723079Z","iopub.status.idle":"2024-11-30T18:29:33.749611Z","shell.execute_reply.started":"2024-11-30T18:29:33.723061Z","shell.execute_reply":"2024-11-30T18:29:33.748712Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Split Data","metadata":{}},{"cell_type":"code","source":"data = pd.concat([file_path, labels], axis=1)\ndata = data.sample(frac=1).reset_index(drop=True)\ntrain_df, test_df = train_test_split(data, test_size=0.2, random_state=2)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:33.752086Z","iopub.execute_input":"2024-11-30T18:29:33.752383Z","iopub.status.idle":"2024-11-30T18:29:33.769177Z","shell.execute_reply.started":"2024-11-30T18:29:33.752351Z","shell.execute_reply":"2024-11-30T18:29:33.768553Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA & Visualization","metadata":{}},{"cell_type":"code","source":"# Create subplots with 4 rows, 4 columns, and a specified figure size\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\n# Iterate through the subplots and display images with corresponding labels\nfor i, ax in enumerate(axes.flat):\n    # Use 'plt.imread' to read and display the image corresponding to the file path in 'data.File_Path[i]'\n    ax.imshow(plt.imread(data.File_Path[i]))\n    \n    # Set the title of the subplot to the corresponding label from 'data.Labels[i]'\n    ax.set_title(data.Labels[i])\n\n# Adjust layout for better visualization\nplt.tight_layout()\n\n# Display the plot\nplt.show()\n\n# Calculate the count of each unique label in the 'Labels' column of the 'data' DataFrame\ncounts = data.Labels.value_counts()\n\n# Use Seaborn to create a bar plot of label counts\nsns.barplot(x=counts.index, y=counts)\n\n# Set the x-axis label\nplt.xlabel('Labels')\n\n# Set the y-axis label\nplt.ylabel('Count')\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=50)\n\n# Display the plot","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:33.770090Z","iopub.execute_input":"2024-11-30T18:29:33.770357Z","iopub.status.idle":"2024-11-30T18:29:35.593652Z","shell.execute_reply.started":"2024-11-30T18:29:33.770336Z","shell.execute_reply":"2024-11-30T18:29:35.592787Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define Functions","metadata":{}},{"cell_type":"markdown","source":"# Data Gen","metadata":{}},{"cell_type":"code","source":"# Define a function 'gen' that takes three parameters: preprocessing function 'pre', training data 'train', and test data 'test'\ndef gen(pre, train, test):\n    # Create an ImageDataGenerator for training data with specified preprocessing function and 20% validation split\n    train_datagen = ImageDataGenerator(preprocessing_function=pre, validation_split=0.2)\n    \n    # Create an ImageDataGenerator for test data with the specified preprocessing function\n    test_datagen = ImageDataGenerator(preprocessing_function=pre)\n    \n    # Generate training data flow using train_datagen.flow_from_dataframe\n    train_gen = train_datagen.flow_from_dataframe(\n        dataframe=train,\n        x_col='File_Path',\n        y_col='Labels',\n        target_size=(100, 100),\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=True,\n        seed=0,\n        subset='training',  # Use the subset parameter to specify it's the training set\n        rotation_range=30,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\"\n    )\n    \n    # Generate validation data flow using train_datagen.flow_from_dataframe\n    valid_gen = train_datagen.flow_from_dataframe(\n        dataframe=train,\n        x_col='File_Path',\n        y_col='Labels',\n        target_size=(100, 100),\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=False,  # Set shuffle to False for validation set\n        seed=0,\n        subset='validation',  # Use the subset parameter to specify it's the validation set\n        rotation_range=30,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\"\n    )\n    \n    # Generate test data flow using test_datagen.flow_from_dataframe\n    test_gen = test_datagen.flow_from_dataframe(\n        dataframe=test,\n        x_col='File_Path',\n        y_col='Labels',\n        target_size=(100, 100),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        verbose=0,  # Set verbose to 0 to suppress output during testing\n        shuffle=False  # Set shuffle to False for test set\n    )\n    \n    # Return the generated training, validation, and test data generators\n    return train_gen, valid_gen, test_gen","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:35.594678Z","iopub.execute_input":"2024-11-30T18:29:35.594930Z","iopub.status.idle":"2024-11-30T18:29:35.602102Z","shell.execute_reply.started":"2024-11-30T18:29:35.594908Z","shell.execute_reply":"2024-11-30T18:29:35.601210Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model parameter","metadata":{}},{"cell_type":"code","source":"# Define a function 'func' that takes the model name as a parameter\ndef func(name_model):\n    # Create a pre-trained model with specified configuration\n    pre_model = name_model(input_shape=(100, 100, 3),\n                           include_top=False,\n                           weights='imagenet',\n                           pooling='avg')\n    \n    # Freeze the layers of the pre-trained model\n    pre_model.trainable = False\n    \n    # Define model inputs as the inputs of the pre-trained model\n    inputs = pre_model.input\n    \n    # Add additional dense layers on top of the pre-trained model\n    x = Dense(100, activation='relu')(pre_model.output)\n    x = Dense(100, activation='relu')(x)\n    \n    # Define the model outputs\n    outputs = Dense(10, activation='softmax')(x)\n    \n    # Create the final model using the pre-trained model and added layers\n    model = Model(inputs=inputs, outputs=outputs)\n    \n    # Compile the model with specified loss, optimizer, and metrics\n    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n    \n    # Define early stopping callback to prevent overfitting\n    my_callbacks = [EarlyStopping(monitor='val_loss',\n                                  min_delta=0,\n                                  patience=100,\n                                  mode='auto')]\n    \n    # Return the compiled model and the early stopping callback\n    return model, my_callbacks","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:35.602997Z","iopub.execute_input":"2024-11-30T18:29:35.603327Z","iopub.status.idle":"2024-11-30T18:29:35.629604Z","shell.execute_reply.started":"2024-11-30T18:29:35.603306Z","shell.execute_reply":"2024-11-30T18:29:35.628780Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Drawing Plots","metadata":{}},{"cell_type":"code","source":"# Define a function 'plot' that takes history, test_gen, train_gen, model, and test_df as parameters\ndef plot(history, test_gen, train_gen, model, test_df):\n    # Plotting Accuracy and Loss over epochs\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n    ax = ax.ravel()\n\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(history.history[met])\n        ax[i].plot(history.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['Train', 'Validation'])\n    \n    # Predictions on the test data\n    pred = model.predict(test_gen)\n    pred = np.argmax(pred, axis=1)\n    \n    # Convert numerical labels back to original class labels\n    labels = (train_gen.class_indices)\n    labels = dict((v, k) for k, v in labels.items())\n    pred = [labels[k] for k in pred]\n    \n    # Classification report\n    cm = confusion_matrix(test_df.Labels, pred)\n    clr = classification_report(test_df.Labels, pred)\n    print(clr)\n    \n    # Display 12 pictures of the dataset with their true and predicted labels\n    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(12, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(plt.imread(test_df.File_Path.iloc[i+1]))\n        ax.set_title(f\"True: {test_df.Labels.iloc[i+1]}\\nPredicted: {pred[i+1]}\")\n    plt.tight_layout()\n    plt.show()\n    \n    # Return the training history for potential further analysis or plotting\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:35.630748Z","iopub.execute_input":"2024-11-30T18:29:35.631100Z","iopub.status.idle":"2024-11-30T18:29:35.643650Z","shell.execute_reply.started":"2024-11-30T18:29:35.631075Z","shell.execute_reply":"2024-11-30T18:29:35.642919Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Result View","metadata":{}},{"cell_type":"code","source":"# Define a function 'result_test' that takes 'test' (test data) and 'model_use' (the trained model) as parameters\ndef result_test(test, model_use):\n    # Evaluate the model on the test data\n    results = model_use.evaluate(test, verbose=0)\n    \n    # Print the test loss and accuracy\n    print(\"    Test Loss: {:.5f}\".format(results[0]))\n    print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n    \n    # Return the evaluation results for potential further analysis or reporting\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-11-30T18:29:35.644543Z","iopub.execute_input":"2024-11-30T18:29:35.644771Z","iopub.status.idle":"2024-11-30T18:29:35.656875Z","shell.execute_reply.started":"2024-11-30T18:29:35.644750Z","shell.execute_reply":"2024-11-30T18:29:35.656031Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EfficientNet B7","metadata":{}},{"cell_type":"code","source":"### Assuming you have imported your data and created the train and test DataFrames (train_df and test_df)\n\n# Generate data for EfficientNetB7\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\nENet_pre = preprocess_input\ntrain_gen_ENet, valid_gen_ENet, test_gen_ENet = gen(ENet_pre, train_df, test_df)\nENet_model, callback_ENet = func(DenseNet201)\n\n# Modified training loop to include per-epoch accuracy printing and validation accuracy printing at each step\nhistory_ENet = ENet_model.fit(\n    train_gen_ENet,\n    validation_data=valid_gen_ENet,\n    epochs=100,\n    callbacks=callback_ENet,\n    verbose=1,  # Set to 1 for per-epoch accuracy printing\n    steps_per_epoch=len(train_gen_ENet),\n    validation_steps=len(valid_gen_ENet)\n)\n\nhistory_ENet = plot(history_ENet, test_gen_ENet, train_gen_ENet, ENet_model, test_df)\nresult_ENet = result_test(test_gen_ENet, ENet_model)\n\n# Define a function to plot confusion matrix\ndef plot_confusion_matrix(y_true, y_pred, classes, model_name):\n    cm = confusion_matrix(y_true, y_pred)\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n    plt.title(f\"Confusion Matrix - {model_name}\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n\n# Assuming you have the true labels and predicted labels for EfficientNetB7\ntrue_labels_ENet = test_gen_ENet.classes\npredictions_ENet = ENet_model.predict(test_gen_ENet)\npredicted_labels_ENet = predictions_ENet.argmax(axis=1)\n\n# Display confusion matrix with full model name for EfficientNetB7\nfull_model_name_ENet = \"EfficientNetB7\"\nplot_confusion_matrix(true_labels_ENet, predicted_labels_ENet, classes=test_gen_ENet.class_indices.keys(), model_name=full_model_name_ENet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T18:29:35.659167Z","iopub.execute_input":"2024-11-30T18:29:35.659475Z","iopub.status.idle":"2024-11-30T19:03:38.262497Z","shell.execute_reply.started":"2024-11-30T18:29:35.659454Z","shell.execute_reply":"2024-11-30T19:03:38.261619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the EfficientNetB7 model\nENet_model.save(\"models/EfficientNetB7.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T19:03:38.263696Z","iopub.execute_input":"2024-11-30T19:03:38.263968Z","iopub.status.idle":"2024-11-30T19:03:39.374272Z","shell.execute_reply.started":"2024-11-30T19:03:38.263945Z","shell.execute_reply":"2024-11-30T19:03:39.373320Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DenseNet 201","metadata":{}},{"cell_type":"code","source":"# Generate data for DenseNet201\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications.densenet import preprocess_input\n\nDenseNet201_pre = preprocess_input\ntrain_gen_DenseNet201, valid_gen_DenseNet201, test_gen_DenseNet201 = gen(DenseNet201_pre, train_df, test_df)\nDenseNet201_model, callback_DenseNet201 = func(DenseNet201)\n\nhistory_DenseNet201 = DenseNet201_model.fit(\n    train_gen_DenseNet201,\n    validation_data=valid_gen_DenseNet201,\n    epochs=100,\n    callbacks=callback_DenseNet201,\n    verbose=1,\n    steps_per_epoch=len(train_gen_DenseNet201),\n    validation_steps=len(valid_gen_DenseNet201)\n)\n\nhistory_DenseNet201 = plot(history_DenseNet201, test_gen_DenseNet201, train_gen_DenseNet201, DenseNet201_model, test_df)\nresult_DenseNet201 = result_test(test_gen_DenseNet201, DenseNet201_model)\n\n# Assuming your test_gen_DenseNet201 yields both input images and labels\ntrue_labels_DenseNet201 = test_gen_DenseNet201.classes\npredictions_DenseNet201 = DenseNet201_model.predict(test_gen_DenseNet201)\npredicted_labels_DenseNet201 = predictions_DenseNet201.argmax(axis=1)\n\n# Display confusion matrix with full model name for DenseNet201\nfull_model_name_DenseNet201 = \"DenseNet201\"\nplot_confusion_matrix(true_labels_DenseNet201, predicted_labels_DenseNet201, classes=test_gen_DenseNet201.class_indices.keys(), model_name=full_model_name_DenseNet201)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-11-30T19:03:39.376093Z","iopub.execute_input":"2024-11-30T19:03:39.376408Z","iopub.status.idle":"2024-11-30T19:42:25.185604Z","shell.execute_reply.started":"2024-11-30T19:03:39.376384Z","shell.execute_reply":"2024-11-30T19:42:25.184713Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the DenseNet201 model\nDenseNet201_model.save(\"models/DenseNet201.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T19:42:25.186721Z","iopub.execute_input":"2024-11-30T19:42:25.186961Z","iopub.status.idle":"2024-11-30T19:42:26.174286Z","shell.execute_reply.started":"2024-11-30T19:42:25.186940Z","shell.execute_reply":"2024-11-30T19:42:26.173405Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VGG 19","metadata":{}},{"cell_type":"code","source":"# Generate data for VGG19\nfrom tensorflow.keras.applications import VGG19\n\nVGG19_pre = preprocess_input\ntrain_gen_VGG19, valid_gen_VGG19, test_gen_VGG19 = gen(VGG19_pre, train_df, test_df)\nVGG19_model, callback_VGG19 = func(VGG19)\n\nhistory_VGG19 = VGG19_model.fit(\n    train_gen_VGG19,\n    validation_data=valid_gen_VGG19,\n    epochs=100,\n    callbacks=callback_VGG19,\n    verbose=1,\n    steps_per_epoch=len(train_gen_VGG19),\n    validation_steps=len(valid_gen_VGG19)\n)\n\nhistory_VGG19 = plot(history_VGG19, test_gen_VGG19, train_gen_VGG19, VGG19_model, test_df)\nresult_VGG19 = result_test(test_gen_VGG19, VGG19_model)\n\n# Assuming your test_gen_VGG19 yields both input images and labels\ntrue_labels_VGG19 = test_gen_VGG19.classes\n\n# Make predictions using the trained VGG19 model\npredictions_VGG19 = VGG19_model.predict(test_gen_VGG19)\n\n# Convert predictions to class labels\npredicted_labels_VGG19 = predictions_VGG19.argmax(axis=1)\n\n# Display confusion matrix with the full model name for VGG19\nfull_model_name_VGG19 = \"VGG19\"\nplot_confusion_matrix(true_labels_VGG19, predicted_labels_VGG19, classes=test_gen_VGG19.class_indices.keys(), model_name=full_model_name_VGG19)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T19:42:26.175632Z","iopub.execute_input":"2024-11-30T19:42:26.175875Z","iopub.status.idle":"2024-11-30T20:14:31.226832Z","shell.execute_reply.started":"2024-11-30T19:42:26.175854Z","shell.execute_reply":"2024-11-30T20:14:31.225932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the VGG19 model\nVGG19_model.save(\"models/VGG19.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T20:14:31.228161Z","iopub.execute_input":"2024-11-30T20:14:31.228857Z","iopub.status.idle":"2024-11-30T20:14:31.383659Z","shell.execute_reply.started":"2024-11-30T20:14:31.228822Z","shell.execute_reply":"2024-11-30T20:14:31.382693Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ResNet 152","metadata":{}},{"cell_type":"code","source":"# Generate data for ResNet152\nfrom tensorflow.keras.applications import ResNet152\n\nResNet152_pre = preprocess_input\ntrain_gen_ResNet152, valid_gen_ResNet152, test_gen_ResNet152 = gen(ResNet152_pre, train_df, test_df)\nResNet152_model, callback_ResNet152 = func(ResNet152)\n\nhistory_ResNet152 = ResNet152_model.fit(\n    train_gen_ResNet152,\n    validation_data=valid_gen_ResNet152,\n    epochs=100,\n    callbacks=callback_ResNet152,\n    verbose=1,\n    steps_per_epoch=len(train_gen_ResNet152),\n    validation_steps=len(valid_gen_ResNet152)\n)\n\nhistory_ResNet152 = plot(history_ResNet152, test_gen_ResNet152, train_gen_ResNet152, ResNet152_model, test_df)\nresult_ResNet152 = result_test(test_gen_ResNet152, ResNet152_model)\n\n# Assuming your test_gen_ResNet152 yields both input images and labels\ntrue_labels_ResNet152 = test_gen_ResNet152.classes\n\n# Make predictions using the trained ResNet152 model\npredictions_ResNet152 = ResNet152_model.predict(test_gen_ResNet152)\n\n# Convert predictions to class labels\npredicted_labels_ResNet152 = predictions_ResNet152.argmax(axis=1)\n\n# Display confusion matrix with the full model name for ResNet152\nfull_model_name_ResNet152 = \"ResNet152\"\nplot_confusion_matrix(true_labels_ResNet152, predicted_labels_ResNet152, classes=test_gen_ResNet152.class_indices.keys(), model_name=full_model_name_ResNet152)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T20:14:31.384685Z","iopub.execute_input":"2024-11-30T20:14:31.384912Z","iopub.status.idle":"2024-11-30T20:51:17.727151Z","shell.execute_reply.started":"2024-11-30T20:14:31.384892Z","shell.execute_reply":"2024-11-30T20:51:17.726322Z"},"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the ResNet152 model\nResNet152_model.save(\"models/ResNet152.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T20:51:17.728447Z","iopub.execute_input":"2024-11-30T20:51:17.728818Z","iopub.status.idle":"2024-11-30T20:51:18.807404Z","shell.execute_reply.started":"2024-11-30T20:51:17.728785Z","shell.execute_reply":"2024-11-30T20:51:18.806672Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inception V3","metadata":{}},{"cell_type":"code","source":"# Generate data for InceptionV3\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\nInceptionV3_pre = preprocess_input\ntrain_gen_InceptionV3, valid_gen_InceptionV3, test_gen_InceptionV3 = gen(InceptionV3_pre, train_df, test_df)\nInceptionV3_model, callback_InceptionV3 = func(InceptionV3)\n\nhistory_InceptionV3 = InceptionV3_model.fit(\n    train_gen_InceptionV3,\n    validation_data=valid_gen_InceptionV3,\n    epochs=100,\n    callbacks=callback_InceptionV3,\n    verbose=1,\n    steps_per_epoch=len(train_gen_InceptionV3),\n    validation_steps=len(valid_gen_InceptionV3)\n)\n\nhistory_InceptionV3 = plot(history_InceptionV3, test_gen_InceptionV3, train_gen_InceptionV3, InceptionV3_model, test_df)\nresult_InceptionV3 = result_test(test_gen_InceptionV3, InceptionV3_model)\n\n# Assuming your test_gen_InceptionV3 yields both input images and labels\ntrue_labels_InceptionV3 = test_gen_InceptionV3.classes\npredictions_InceptionV3 = InceptionV3_model.predict(test_gen_InceptionV3)\npredicted_labels_InceptionV3 = predictions_InceptionV3.argmax(axis=1)\n\n# Display confusion matrix with the full model name for InceptionV3\nfull_model_name_InceptionV3 = \"InceptionV3\"\nplot_confusion_matrix(true_labels_InceptionV3, predicted_labels_InceptionV3, classes=test_gen_InceptionV3.class_indices.keys(), model_name=full_model_name_InceptionV3)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T20:51:18.808674Z","iopub.execute_input":"2024-11-30T20:51:18.808901Z","iopub.status.idle":"2024-11-30T21:22:52.016363Z","shell.execute_reply.started":"2024-11-30T20:51:18.808881Z","shell.execute_reply":"2024-11-30T21:22:52.015408Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the InceptionV3 model\nInceptionV3_model.save(\"models/InceptionV3.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T21:22:52.017570Z","iopub.execute_input":"2024-11-30T21:22:52.017830Z","iopub.status.idle":"2024-11-30T21:22:52.566455Z","shell.execute_reply.started":"2024-11-30T21:22:52.017807Z","shell.execute_reply":"2024-11-30T21:22:52.565413Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **MobileNet V2**","metadata":{}},{"cell_type":"code","source":"# Generate data for MobileNetV2\nfrom tensorflow.keras.applications import MobileNetV2\n\nMobileNetV2_pre = preprocess_input\ntrain_gen_MobileNetV2, valid_gen_MobileNetV2, test_gen_MobileNetV2 = gen(MobileNetV2_pre, train_df, test_df)\nMobileNetV2_model, callback_MobileNetV2 = func(MobileNetV2)\n\nhistory_MobileNetV2 = MobileNetV2_model.fit(\n    train_gen_MobileNetV2,\n    validation_data=valid_gen_MobileNetV2,\n    epochs=100,\n    callbacks=callback_MobileNetV2,\n    verbose=1,\n    steps_per_epoch=len(train_gen_MobileNetV2),\n    validation_steps=len(valid_gen_MobileNetV2)\n)\n\nhistory_MobileNetV2 = plot(history_MobileNetV2, test_gen_MobileNetV2, train_gen_MobileNetV2, MobileNetV2_model, test_df)\nresult_MobileNetV2 = result_test(test_gen_MobileNetV2, MobileNetV2_model)\n\n# Assuming your test_gen_InceptionV3 yields both input images and labels\ntrue_labels_MobileNetV2 = test_gen_MobileNetV2.classes\npredictions_MobileNetV2 = MobileNetV2_model.predict(test_gen_MobileNetV2)\npredicted_labels_MobileNetV2 = predictions_MobileNetV2.argmax(axis=1)\n\n# Display confusion matrix with the full model name for MobileNetV2\nfull_model_name_MobileNetV2 = \"MobileNetV2\"\nplot_confusion_matrix(true_labels_MobileNetV2, predicted_labels_MobileNetV2, classes=test_gen_MobileNetV2.class_indices.keys(), model_name=full_model_name_MobileNetV2)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T21:22:52.568085Z","iopub.execute_input":"2024-11-30T21:22:52.568384Z","iopub.status.idle":"2024-11-30T21:53:46.364150Z","shell.execute_reply.started":"2024-11-30T21:22:52.568359Z","shell.execute_reply":"2024-11-30T21:53:46.363180Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the MobileNetV2 model\nMobileNetV2_model.save(\"models/MobileNetV2.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T21:53:46.365177Z","iopub.execute_input":"2024-11-30T21:53:46.365430Z","iopub.status.idle":"2024-11-30T21:53:46.658987Z","shell.execute_reply.started":"2024-11-30T21:53:46.365409Z","shell.execute_reply":"2024-11-30T21:53:46.658312Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Xception**","metadata":{}},{"cell_type":"code","source":"# Generate data for Xception\nfrom tensorflow.keras.applications import Xception\n\nXception_pre = preprocess_input\ntrain_gen_Xception, valid_gen_Xception, test_gen_Xception = gen(Xception_pre, train_df, test_df)\nXception_model, callback_Xception = func(Xception)\n\nhistory_Xception = Xception_model.fit(\n    train_gen_Xception,\n    validation_data=valid_gen_Xception,\n    epochs=100,\n    callbacks=callback_Xception,\n    verbose=1,\n    steps_per_epoch=len(train_gen_Xception),\n    validation_steps=len(valid_gen_Xception)\n)\n\nhistory_Xception = plot(history_Xception, test_gen_Xception, train_gen_Xception, Xception_model, test_df)\nresult_Xception = result_test(test_gen_Xception, Xception_model)\n\n# Assuming your test_gen_InceptionV3 yields both input images and labels\ntrue_labels_Xception = test_gen_Xception.classes\npredictions_Xception = Xception_model.predict(test_gen_Xception)\npredicted_labels_Xception = predictions_Xception.argmax(axis=1)\n\n# Display confusion matrix with the full model name for Xception\nfull_model_name_Xception = \"Xception\"\nplot_confusion_matrix(true_labels_Xception, predicted_labels_Xception, classes=test_gen_Xception.class_indices.keys(), model_name=full_model_name_Xception)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T21:53:46.660402Z","iopub.execute_input":"2024-11-30T21:53:46.660739Z","iopub.status.idle":"2024-11-30T22:25:05.612949Z","shell.execute_reply.started":"2024-11-30T21:53:46.660708Z","shell.execute_reply":"2024-11-30T22:25:05.611917Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the Xception model\nXception_model.save(\"models/Xception.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T22:25:05.614150Z","iopub.execute_input":"2024-11-30T22:25:05.614427Z","iopub.status.idle":"2024-11-30T22:25:05.966963Z","shell.execute_reply.started":"2024-11-30T22:25:05.614400Z","shell.execute_reply":"2024-11-30T22:25:05.966237Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Zip and Download","metadata":{}},{"cell_type":"code","source":"z = '/kaggle/working/models'\nshutil.make_archive(z, 'zip', z)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T22:25:05.968117Z","iopub.execute_input":"2024-11-30T22:25:05.968390Z","iopub.status.idle":"2024-11-30T22:25:37.867336Z","shell.execute_reply.started":"2024-11-30T22:25:05.968368Z","shell.execute_reply":"2024-11-30T22:25:37.866520Z"},"trusted":true},"outputs":[],"execution_count":null}]}